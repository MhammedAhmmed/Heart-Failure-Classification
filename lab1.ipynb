{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c675a8-cc8b-4309-96ec-23e6b76a65bc",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fc7a3bb-342b-4ab1-9c5e-cb1e3f06526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b01b7e-54b9-4666-9d3f-d818bb284d23",
   "metadata": {},
   "source": [
    "## Show downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59b3af83-60cf-4587-b23e-1e48802e1dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"archive/heart.csv\")\n",
    "print(df.head())  # Show the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc8f16-b7c0-4571-9bc3-17320e597bb5",
   "metadata": {},
   "source": [
    "## Split data into trainging, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bf86fbc-a499-4347-86d2-fc081950e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: 918 samples\n",
      "Training set: 642 samples\n",
      "Validation set: 92 samples\n",
      "Testing set: 184 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split 70% training, 30% temp (validation + test)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42) # using random_state(42) to garantie same splitting data\n",
    "\n",
    "# Step 2: Split temp into 10% validation and 20% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=2/3, random_state=42)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Total dataset: {len(df)} samples\")\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(val_df)} samples\")\n",
    "print(f\"Testing set: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72aefa-9640-4b88-9ca3-8443ed4c9c0b",
   "metadata": {},
   "source": [
    "## Decision tree implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6369fba-d5fb-4b50-a85a-1ecade18602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Node to identify if it is internal node to split or leaf node to predict\"\"\"\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "\n",
    "    @classmethod\n",
    "    def leaf(cls, label):\n",
    "        return cls(label = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be0900fa-3254-477b-9ab7-6b5eb101ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"Compute the entropy (H)\"\"\"\n",
    "        # Count 0s, and 1s\n",
    "        _, counts = np.unique(y, return_counts = True)\n",
    "        # Compute probabilities of 0s, and 1s\n",
    "        probs = counts / counts.sum()\n",
    "        # Get the entropy\n",
    "        return -np.sum(probs * np.log2(probs + 1e-9)) # Adding small number to avoid log of zero\n",
    "\n",
    "    def information_gain(self, y, left_split, right_split):\n",
    "        \"\"\"Compute information gain (IG)\"\"\"\n",
    "        # Compute H(Y)\n",
    "        H_Y = self.entropy(y)\n",
    "        # Compute H(Y|X = left)\n",
    "        H_Y_left = self.entropy(y[left_split])\n",
    "        # Compute H(Y|X = right)\n",
    "        H_Y_right = self.entropy(y[right_split])\n",
    "        # Compute H(Y|X)\n",
    "        H_Y_X = (np.sum(left_split) / len(y)) * H_Y_left + (np.sum(right_split) / len(y)) * H_Y_right\n",
    "        # Get the information gain\n",
    "        return H_Y - H_Y_X\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"Find the best numerical split\"\"\"\n",
    "        best_feature, best_threshold, best_IG = None, None, 0\n",
    "        best_left_split, best_right_split = None, None\n",
    "\n",
    "        for feature in range(X.shape[1]):  # Iterate over features\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            \n",
    "            if np.issubdtype(X[:, feature].dtype, np.number):  # ðŸ”¹ Numerical feature\n",
    "                # Sort feature values\n",
    "                unique_values = np.sort(unique_values)\n",
    "                # Try splitting at midpoints between consecutive values\n",
    "                for i in range(len(unique_values) - 1):\n",
    "                    threshold = (unique_values[i] + unique_values[i + 1]) / 2  # Midpoint\n",
    "                    left_split = X[:, feature] <= threshold\n",
    "                    right_split = X[:, feature] > threshold\n",
    "    \n",
    "                    if np.sum(left_split) == 0 or np.sum(right_split) == 0:\n",
    "                        continue  # Skip invalid splits\n",
    "    \n",
    "                    IG = self.information_gain(y, left_split, right_split)\n",
    "                    if IG > best_IG:\n",
    "                        best_IG, best_feature, best_threshold = IG, feature, threshold\n",
    "                        best_left_split, best_right_split = left_split, right_split\n",
    "            \n",
    "            else:  # ðŸ”¹ Categorical feature\n",
    "                for value in unique_values:\n",
    "                    left_split = X[:, feature] == value\n",
    "                    right_split = ~left_split  \n",
    "    \n",
    "                    if np.sum(left_split) == 0 or np.sum(right_split) == 0:\n",
    "                        continue  \n",
    "    \n",
    "                    IG = self.information_gain(y, left_split, right_split)\n",
    "                    if IG > best_IG:\n",
    "                        best_IG, best_feature, best_threshold = IG, feature, value\n",
    "                        best_left_split, best_right_split = left_split, right_split\n",
    "\n",
    "        return best_feature, best_threshold, best_left_split, best_right_split\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively build the decision tree using threshold splits.\"\"\"\n",
    "        if len(set(y)) == 1:  # If only one class, return leaf node\n",
    "            return Node.leaf(y[0])\n",
    "\n",
    "        if self.max_depth and depth >= self.max_depth:\n",
    "            return Node.leaf(np.bincount(y).argmax())  # Return most common label\n",
    "\n",
    "        feature, threshold, left_split, right_split = self.best_split(X, y)\n",
    "\n",
    "        if feature is None:\n",
    "            return  Node.leaf(np.bincount(y).argmax())  # No valid split\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_subtree = self.build_tree(X[left_split, :], y[left_split], depth + 1)\n",
    "        right_subtree = self.build_tree(X[right_split, :], y[right_split], depth + 1)\n",
    "\n",
    "        \n",
    "        return Node(feature, threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the decision tree.\"\"\"\n",
    "        self.tree = self.build_tree(X, y)\n",
    "\n",
    "    def predict_sample(self, node, x):\n",
    "        \"\"\"Predict a single sample recursively.\"\"\"\n",
    "        if node.label is not None:\n",
    "            return node.label\n",
    "        if isinstance(node.threshold, (int, float)):  # Numeric feature\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                return self.predict_sample(node.left, x)\n",
    "            else:\n",
    "                return self.predict_sample(node.right, x)\n",
    "        else:  # Categorical feature\n",
    "            if x[node.feature] == node.threshold:\n",
    "                return self.predict_sample(node.left, x)\n",
    "            else:\n",
    "                return self.predict_sample(node.right, x)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict multiple samples.\"\"\"\n",
    "        return np.array([self.predict_sample(self.tree, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1c087db-3a96-4761-a514-ed4d16bab843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "data = pd.DataFrame({\n",
    "    'Income': [35, 70, 60, 85, 40, 90],  # Numerical\n",
    "    'CarType': ['Sedan', 'SUV', 'Sedan', 'Sedan', 'SUV', 'SUV'],  # Categorical\n",
    "    'BuysCar': [0, 1, 0, 1, 0, 1]  # Target (0: No, 1: Yes)\n",
    "})\n",
    "\n",
    "# Convert categorical features to numerical (Label Encoding)\n",
    "data['CarType'] = data['CarType'].astype('category').cat.codes  # Sedan=0, SUV=1\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = data[['Income', 'CarType']].values\n",
    "y = data['BuysCar'].values\n",
    "\n",
    "# Train the Decision Tree\n",
    "tree = DecisionTree(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Test Predictions\n",
    "X_test = np.array([[30, 0], [75, 1], [55, 0], [95, 1]])  # Income, CarType\n",
    "predictions = tree.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3a095-2820-4f62-8e1f-54adb79be690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
